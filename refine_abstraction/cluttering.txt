#pass @@2D image to tensor

			#newtest = np.reshape(newtestt, (-1, 28))

			#Printing  @2D image used 

			#imagee = original_image.get_image()
			#Y = np.array(np.float64(imagee))
			#print(Y)
			#X = np.array(np.float64(imagee)/np.float64(255))
			#print(X)
			#print(newtest)
			#rbsaise = np.array(np.float64(test[1:len(test)]))
			#bsaise = np.reshape(rbsaise, (-1, 28))
			
			#print(bsaise)

			#newtest[0] = 1.0
			#newtest[1] = 1.0
			#--------other methods for evaluating tensor#

			#pred = model.eval({inp:newtest})
			#inp = tf.placeholder(tf.float64, [None, 784])
			
			#--------evaluating tensorflow----------------#
			'''for i in range(0,28):
				newtest[0][i]=1.0
				newtest[1][i]=1.0'''
			'''for j in range(0,24):
				for k in range(0,28):
					newtest[j][k]=1.0'''
				------------------------------------------------------

				#pred = model.eval({inp:newtest})
			'''myset = set()
			bias = original_image.get_bias()
			count = 0
			with open("predict_new.txt", "w") as f:
				for fir in pred:
					for sec in fir:
						for thi in sec:
							for fo in thi:
								#count += 1
								f.write(str(fo) + "\n")
								#myset.add(fo)
								#if fo not in bias and fo != 0:
									#print(count)'''

			#print(myset)'''
			----------------------------------------------------------------------
			'''with open("predict.txt", "wb") as fp:
				pickle.dump(pred, fp)
			#print(pred)
			with open("predict.txt", "rb") as fp:
				b = pickle.load(fp)'''
			#print(b)
			#print(pred)
			#print(len(pred))
			#print(len(pred[0]))
			#print(len(pred[0][0]))
			#print(len(pred[0][0][0]))

			--------------------------------------------------------

			def get_next_layer(d):

	imagee = original_image.get_image()
	X = np.array(np.float64(imagee)/np.float64(255))
	padding = 1
	# 	@Padding Applied     #

	padded_image = np.zeros([X.shape[0] +2*padding, X.shape[1]+2*padding])
	padded_image[:X.shape[0],:X.shape[1]] = X

	# 	@Debugging 			#
	#padded_image[1][1] = 1.0
	#padded_image[1][2] = 1.0
	'''for i in range(1,29):
		padded_image[1][i]=1.0
		padded_image[2][i]=1.0'''

	'''for j in range(1,25):
		for k in range(1,29):
			padded_image[j][k]= 1.0'''

	#--------------printting the padded image------------------#
	#print(padded_image)
	#print(padded_image.shape)

	#		@kernals used 			#

	kernal_x = len(d)
	kernal_y = len(d[0])
	stride = 2
	bias = original_image.get_bias()

	#		 @4 * 4 Kernal for multiplication	#
	
	ker = [[[0 for k in range(4)] for i in range(4)] for j in range(32)]

	kernal = np.array(np.float64(ker))
	#kernal = np.array(ker, dtype = float)
	
	for i in range(len(d)):
		for j in range(len(d[0])):
			t = d[i][j][0]
			for k in range(len(t)):
				kernal[k][i][j] = t[k]

	ans = [[[0 for k in range(14)] for i in range(14)] for j in range(32)]
	ans = np.array(np.float64(ans))
	#ans = np.array(ans, dtype = float64)

	i = 0
	j = 0
	pos_x = 0
	pos_y = 0
	while i <= padded_image.shape[0] - kernal_x :
		
		pos_y = 0
		j = 0
		while j <= padded_image.shape[1] - kernal_y :
			
			# 4 * 4 image for multiplication
			xx = [im[j:j+kernal_y] for im in padded_image[i:i+kernal_x]]
			req_image = np.array(xx)
			for ker in range(32):
				final = np.multiply(req_image,kernal[ker])
				finalvalue = np.sum(final)
				ans[ker][pos_x][pos_y] = finalvalue + bias[ker]
				# for debugging check 16 values
				if ker == 5 and pos_x == 2 and pos_y == 5:
					print(xx)
					print(i)
					print(j)
					print(kernal[5])
					print(bias[5])
					final = np.multiply(req_image,kernal[5])
					finalvalue = np.sum(final)
					print(final)
					print(finalvalue)
					anss = finalvalue + bias[5]
					print("check the va")
					print(anss)
			j += stride
			pos_y += 1
		pos_x += 1
		i+=stride
	print(ans.shape)

	with open("myresult.txt", "w") as f:
		for ker in ans:
			for row in ker:
				for ele in row:
					f.write(str(ele) + "\n")
	with open("mynewresult_new.txt", "w") as f:
		k_len = len(ans)
		i_len = len(ans[0])
		j_len = len(ans[0][0])
		#as we have to check 1043th value find the 
		#corresponding kernal, i ,j at 1043th value
		countt = 0
		for i in range(0, i_len):
			for j in range(0, j_len):
				for k in range(0, k_len):
					countt += 1
					if countt == 1062:
						print("get the values")
						print(i)
						print(j)
						print(k)
					if(ans[k][i][j] < 0):
						f.write(str(0.0) +"\n")
					else:
						f.write(str(ans[k][i][j]) + "\n")

						----------------------

						#print(model.summary())
	'''-------'''
	#predict = tf.argmax(model, 1)

-------------------------------------------------
run neural network

'''@ their code @'''
#eran = ERAN(model, is_onnx=False)	
#label,nn,nlb,nub = eran.analyze_box(newtest,newtest, 'deepzono', 1, 1, True)
#print("classified label:" + str(label))
'''
with tf.Session() as sess:
pred = sess.run(model, feed_dict={inp: newtest})
'''
-------------------------------------------------
image without division

#newtest = np.array(np.float64(test[1:len(test)]))

--------------------------------------------------

different returns from read net file


#model, _, means, stds = read_tensorflow_net(netname, 784, True)  #actual
#model, inp, means, stds = read_tensorflow_net(netname, 784, True)#N
#model, d, inp, means, stds = read_tensorflow_net(netname, 28, True)#N
-----------------------------------------------------
find position of max value in list 

#index = np.where(newpred == maximum)
------------------------------------------------------
some important imports

#sys.setrecursionlimit(1000000000)
#sys.path.insert(0, '../../Downloads/semester-2/Refinement/ERAAn/ERAN/ELINA/python_interface/')
#sys.path.insert(0, '../../Downloads/semester-2/Refinement/ERAAn/ERAN/deepg/code/')
#sys.path.insert(1, '../../Downloads/semester-2/Refinement/ERAAn/ERAN/tf_verify')
#from eran import ERAN
#import __main__
#from read_zonotope_file import read_zonotope

------------------------------------------------------

s.add(epsilon*var + img[numb] >= 0,epsilon*var + img[numb] <= 1)


----------------------------------------------------------

 solve_cons_inner(maxsa,len(ls_val[1]), len(ls_val[2]), ls_val, internal_cons, eta_set)
 --------
 new code

 # for x in range(0, 50):
        #         t = "(" + str(x) + ")"+ "_0_b"
        #         u = "(" + str(x) + ")" + "_1_b"
        #         print(t)
        #         t = Bool(t)
        #         u = Bool(u)
        #         print(str(mod[t]) + " " + str(mod[u]))
        # for x in eta_set:
        #         t = 'eps' + str(x)
        #         u = t  + 'dd'
        #         t = Real(t)
        #         u = Real(u)
        #         res = mod[t]
        #         res2 = mod[u]
        #         print(str(x) + ':' + str(res)  +  '   ' + str(res2))
--------------------------------------------------------------------------------


# for i, test in enumerate(tests):
        #         if i == 0:
--------------------------------------------------------------------------------


# if maxsa.check() == sat:
        #         m = maxsa.model()
        #         print(m)
        # else:
        #         print("unsat")
---------------------------------------------------------------------------------


# set_option(max_args=10000000, max_lines=1000000, max_depth=10000000, max_visited=1000000)
---------------------------------------------------------------------------------

 # exit()
 # newm = sorted ([(d, m[d]) for d in m], key = lambda x: (len(str(x[0])), str(x[0])))

 ---------------------------------------------------------------------------------
parsing code
 # print(nodes[ind] == ls_obj[layer][ls_i])
                                # print(str(set_sz) + '   ' + str(len(eta_set)))
                                # print(value)
