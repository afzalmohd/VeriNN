% one paragraph per point
% about 2 pages 



% Current state

% Zoom into deeppoly

% your technique (2 para )


% Experiments:
% tools (why those tools), benchmark, results

% Layout of the rest of the paper


% Why this problem?
\todo{Sometimes we are using textsc and sometime texttt for tool/function names. Make it consistent}
Neural networks are being increasingly used in safety-critical systems such as autonomous vehicles, medical diagnosis, and speech recognition~\cite{bojarski2016end,amato2013artificial,hinton2012deep}. It is important not only that such systems behave correctly in theory but also that they are robust in practice. Unfortunately, it is often the case (see e.g., Goodfellow \cite{goodfellow2014explaining}) that a slight change/perturbation in the input can often fool the neural networks into an error. Such errors can be hard to find/analyze/debug as these neural networks contain hundreds of thousands of non-linear nodes.

% What is the problem?
To address this problem, an entire line of research has emerged focussed on automatically proving (or disproving) the robustness of such networks. Since automatic verification of neural networks is NP-hard~\cite{katz2021reluplex}, researchers use approximations in their methods. Classically, we may divide the methods into two classes, namely complete and incomplete. The methods~\cite{lomuscio2017approach,fischetti2018deep,dutta2018output,cheng2017maximum,katz2017reluplex,katz2019marabou,ehlers2017formal,huang2017safety,wang2021beta,xu2020fast,zhang2022general} are complete. Since complete methods explore exact state space, they suffer from scalability issues on large-scale networks. On the other hand, abstraction based methods e.g., \cite{dvijotham2018dual}, \cite{gehr2018ai2}, \cite{singh2018fast},  \cite{singh2018boosting}, \cite{weng2018towards}, \cite{wong2018provable}, \cite{zhang2018efficient}, \cite{zhang2018efficient} are sound and incomplete, because they over-approximate the state space, but they scale extremely well to large benchmarks. A representative method \deeppoly{}~\cite{singh2019abstract} maintains and propagates upper and lower bound constraints using the so-called triangle approximation (also see Section~\ref{sec:deeppoly}). This is also sometimes called bound-propagation. %a single upper and a single lower linear constraint as well as lower and upper bounds for each neuron in the network. For an affine neuron, the upper and lower constraints are the same as an affine expression, which is a weighted sum of the input neurons. For a $\relu${} neuron, upper and lower constraints are constructed by the so-called triangle approximation.
Unsurprisingly, \deeppoly{} and other abstraction based methods suffer from imprecision. Hence, the methods \cite{wang2018formal,wang2018efficient,elboher2020abstraction,yang2021improving,lin2020art} refine the over-approximated state space to achieve completeness. In \cite{wang2018formal,wang2018efficient,lin2020art} the authors eliminate the spurious information (i.e., imprecision introduced by abstraction) by bisecting the input space on the guided dimension. In~\cite{yang2021improving}, which also works on top of \deeppoly{}~\cite{singh2019abstract}, the authors remove the spurious region by  conjuncting each neuron's constraints with the negation of the robustness property and using an \milp{} (mixed integer linear programming) optimizer Gurobi~\cite{gurobioptimizer} to refine the bounds of neurons. Another work that refines
%The papers also do the refinement on
\deeppoly{} %are \texttt{deepSRGR}~\cite{yang2021improving} and
is \texttt{kPoly}~\cite{singh2019beyond} which considers 
a group of neurons at once to generate the constraints and compute the bounds of neurons. One issue with all these approaches is that the refinement is not guided by previous information/runs and hence they still suffer from scalability issues.
% although these papers do not do the cegar-based refinement.
%The approach \texttt{refinepoly}



% In the refinement, process authors split the merged neurons.  
% In the worst case, this method may get back to the original network.  
% Although this work is a cegar-based approach\todo{afzal, this part is unclear still}, 
% it also suffers from scalability issues on large-scale networks. %  The work \cite{elboher2020abstraction} refinement process focuses on the structure of the networks.

In this paper, we consider the basic abstraction framework provided by \deeppoly{} and develop a novel refinement technique that is {\em counterexample guided}, i.e., we use counterexamples generated from imprecisions during abstraction to guide the refinement process. Our main contributions are the following:
\begin{itemize}
\item We introduce a new {\em maxsat-based} technique to find the cause of imprecision and spuriousness. Starting with an input where the abstraction does not get verified (we use a \milp{} solver to obtain this), we check whether the input generates a real counterexample of falsification of the property or if it is spurious, by executing the neural net. If it is a spurious counterexample, we identify the neuron or the set of neurons that caused it.  
\item We use these specially identified or {\em marked} neurons to split and refine. This ensure that, unlike earlier refinement methods, our method progresses at each iteration and eliminates spurious counterexamples.
\item We adapt the existing refinement framework built on ideas from \milp{}-methods and implement this as a counterexample guided abstraction refinement algorithm on top of \deeppoly{}.
\item We show that our technique outperforms to-the-best-of-our-knowledge all existing refinement strategies based on \deeppoly{}. <some statistics \todo{afzal add stats here} here>
\item We further demonstrate that our implementation is able to verify benchmarks that are beyond the reach of the best state-of-the-art tools, as discussed next.
\end{itemize}
%Thus, whenever \deeppoly{} fails to verify a property, we conjunct the linear constraints generated by it with the negation of the property, and check for satisfiability, by using an \milp{}-based tool.  If the tool return \unsat{} then we report property \texttt{verified}. Otherwise, we go to the refinement process. We have two parts of our refinement approach, one finds the causes of spurious information  and the second part refines the information gets in the first part.

%Given our focus on the cause of spuriousness, let us now explain at a high level what our counterexamples are and how we use them. TOREWRITE: PICTURE AND EXPLANATION HERE.


\medskip

\noindent{\em Related work.}
Another extremely successful line of research has been to revisit the branching heuristics for refinement and use ideas from convex optimization instead of linear or mixed integer linear programming. Starting from a slightly different abstraction/bound propagation method CROWN~\cite{crown}, the work in \cite{betacrown} adopts this approach. This is amenable to parallelizing and hence good for GPU implementation~\cite{gpucrown}. Recently using cutting planes to improve further the refinement analysis has resulted in solving more benchmarks, even at the cost of speed~\cite{cutting-planes}. The success of this approach can be seen by the fact that the state-of-the-art tool ABCROWN\todo{add citations and change macro for ABCROWN} (a portfolio solver, that uses a collection of different parametrized and optimized algorithms) has won the VNNCOMP in a very competitive field of leading tools for robustness verification. Despite this success, there still many benchmarks that are out of reach of the highly optimized ABCROWN. Surprisingly, we show that 180 benchmarks that cannot be solved by ABCROWN can be solved by our tool. The reason is that our focus is on identifying the source of imprecision, which is in some sense, orthogonal to ABCROWN's focus on techniques to fix the imprecisions. Integrating our counterexample guided approach for imprecision-identification with ABCROWN's convex optimization based refinement strategies would be the next step towards wider coverage and performance.%As a next step, our goal Hence we believe that these ideas are orthogonal. 

As mentioned earlier, \texttt{deepSRGR}~\cite{yang2021improving} and \texttt{kPoly}~\cite{singh2019beyond} also use refinement of \deeppoly{} but they are not counterexample guided. Elboher et al~\cite{elboher2020abstraction} and \texttt{NARv}~\cite{liu2022abstraction} do perform counterexample guided abstraction refinement, but their abstraction techniques are orthogonal to \deeppoly{}.  They reduce the network size by merging similar  neurons with over-approximation, while \deeppoly{} maintains the linear constraints for each neuron without changing the structure of the network. These approaches also suffers from scalability issues on large-scale networks.
%Paper~\cite{lin2020art} do the refinement by bisecting the input space on the guided dimension.  Our approach exploits the incomplete technique \deeppoly{}, which scales well, but if it fails to verify then we do the cegar-based refinement.

%% Finally, Elbohar et.al. \cite{elboher2020abstraction} define four classes of neurons based on their 
%% characteristics.
%% At the time of abstraction, they merge each neuron into one of the four classes.  
%% After completing the abstraction process, they use the state of the complete verifier to verify  
%% the abstract network, and go to the refinement process in case of failure. 
%% In case of failure,  authors get an input point that is not a counterexample on the original network 
%% but a counterexample on the abstract network. They execute the input point on both abstract and original networks and 
%% note the value of each neuron. For each neuron, authors compute the difference between its value on the original
%% network with the corresponding merged neuron's value on the abstract network. The authors also consider the difference between the input edge weight with the corresponding
%% merge neuron's input edge weight. They multiply the neuron's value difference and incoming edge difference
%% for each neuron and split the one with a higher value. In the worst case, this method may get back to the original network.
%% Although this work is a cegar-based approach,\todo{please check the para now; Ashutosh: this is too long discussing a single method.} 
%% it also suffers from scalability issues on large-scale networks.   


\noindent{\em Structure of the paper.} We start with a motivating example in the next section~\ref{sec:motivation}.  We define the notions and definitions in section~\ref{sec:model}. The section~\ref{sec:algo} contains the  algorithm procedure of our approach and section~\ref{sec:experiments} contains the experiments. 
We end with future work in Section \ref{sec:conclusion}.



% --- do not erase below this line ----

%%% Local Variables:
%%% mode: latex
%%% TeX-master: "../main"
%%% End:
