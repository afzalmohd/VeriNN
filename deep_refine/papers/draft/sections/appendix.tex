\onecolumn

\begin{center}
    \Large{\bf{Appendix}}    
\end{center}


\subsubsection{Pullback approach: }

Suppose the abstractCEX is $\boldsymbol{v_0}, \boldsymbol{v_1}, ... , \boldsymbol{v_k}$. 
The core idea of this approach is to find a point $\boldsymbol{p_{k-1}}$ in the layer $l_{k-1}$. 
The point $\boldsymbol{v_k}$ is guaranteed to be reachable from point $\boldsymbol{p_{k-1}}$ in the concrete domain.
Similarly, we find points $\boldsymbol{p_{k-3}}, \boldsymbol{p_{k-5}}, ... \boldsymbol{p_0}$, 
such that $p_i$ is always reachable from point $p_{i-2}$. 
We find these points on each \relu{} layer and input layer only. 
If we find the point $\boldsymbol{p_0}$ in the input layer, it means $\boldsymbol{p_0}$ is a counter-example, 
because we can reach from $\boldsymbol{p_0}$ to $\boldsymbol{p_2}$, $\boldsymbol{p_2}$ to $\boldsymbol{p_4}$ 
, and so on up to $\boldsymbol{v_k}$. 
If we get stuck in some layer $l_i$ i.e. fails to find point 
$\boldsymbol{p_{i-2}}$. It means point $\boldsymbol{p_i}$ does not have its corresponding point $\boldsymbol{p_{i-2}}$, 
which implies that point $\boldsymbol{p_i}$ is a spurious point generated by \relu{} layer $l_i$. 
The algorithm \ref{algo:refine1} compute such points. In line number $2$, we equate the value of 
each element of $\boldsymbol{v_k}$ to the corresponding neuron's affine expression($lexpr$ or $uexpr$), 
and take the conjunction, and check satisfiability. Since the affine expression of each neuron in $l_k$ contains the 
variable of layer $l_{i-1}$, so, the satisfying assignment is the point $p_{k-1}$. Similarly, we build the constraints
for each hidden affine layer's neurons. For a neuron $n_{ij}$ of affine layer $l_i$, 
if the corresponding point's value $p_{i+1}(j)$ is greater than $0$ then we equate the affine expression of $x_{ij}$ to $p_{i+1}(j)$,
otherwise, we set the lower and upper bound of the affine expression of $x_{ij}$ as $A(x_{ij}).lb$ and $0$ respectively. 
Which is the replication of \relu{} function $x_{(i+1)j} = max(0, x_{ij})$. We construct such constraint 
for each neuron of $l_i$, and build a formula by taking the conjunction
of each neuronâ€™s constraint and checking the satisfiability of this formula.
If it is satisfiable then the point $\boldsymbol{p_{i-1}}$ is found, 
otherwise, we get the $\mathtt{unsat}$core. We collect all the neurons of $l_i$ whose constraints are 
in $\mathtt{unsat}$core, and return them as the markedNeurons.   



\begin{algorithm}[t]
    \textbf{Name: } pullback \\
    \textbf{Input: } $\langle N,P,Q \rangle$, abstract constraints $A$ and abstractCEX $=\boldsymbol{v_0}, \boldsymbol{v_1}, .., \boldsymbol{v_k}$ \\
    \textbf{Output: } markedNeurons or cex. 
    \begin{algorithmic}[1]
     \State \textbf{return} $\boldsymbol{v_0}$ if $N(\boldsymbol{v_0}) \models \neg Q$. 
     \State $constr := \Land_{j=1}^{|l_k|} (A(x_{kj}).lexpr = v_k(j))$
     \State isSat = checkSat(constr)
     \If{isSat} \Comment{must be true, last affine layer dont add spurious information}
        \State $\boldsymbol{p_{k-1}} = \boldsymbol{satval_{k-1}}$ 
     \EndIf
     \For{$i=k-1$ to $1$}
        \If{$l_i$ is affine layer}
          \State $layerConstraints := true$
          \For{$j=1$ to $|l_i|$}
            \If{$p_{i+1}(j) > 0$}
              \State $constr_{ij}$ := $(A(x_{ij}).lexpr = p_{i+1}(j)$) \Comment{lexpr=uexpr for affine}
            \Else
              \State $constr_{ij}$ := $(A(x_{ij}).lb \leq A(n_{ij}).lexpr \leq 0$)
            \EndIf
            \State $layerConstrains := layerConstrains \land constr_{ij}$
          \EndFor
          \State isSat = checkSat(layerConstrains)
          \If{not isSat}
            \State markedNeurons = \{$n_{ij}$ | $1 \leq j\leq |l_i| \land constr_{ij}$ $\in$ unsatCore\}
            \State \textbf{return } markedNeurons
          \Else
            \State $\boldsymbol{p_{i-1}} = \boldsymbol{satval_{i-1}}$
          \EndIf
        \EndIf
     \EndFor
      \State \textbf{return} $\boldsymbol{p_0}$ \Comment{cex if pullbacked till input layer}
    \end{algorithmic}
    \caption{A pullback approach to get mark neurons or counter example}
    \label{algo:refine1}
  \end{algorithm}