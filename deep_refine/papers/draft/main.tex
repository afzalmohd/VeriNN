\documentclass{llncs}

\input{macro.tex}
%\setlength{\textfloatsep}{1mm}% Remove \textfloatsep

\title{Using counterexamples to improve Robustness Verification in Neural Networks}
\author{}
\institute{}
%\author{Mohammad Afzal\inst{1,2}\and Ashutosh Gupta\inst{1}\and Akshay S\inst{1}\and Supratik Chakraborty\inst{1}}

%\institute{Indian Institute of Technology, Bombay, India\and TCS Research, Pune, India}
% \date{April 2021}

\begin{document}


\maketitle

\begin{abstract}
  Given the pervasive use of neural networks in safety-critical systems it is important to ensure that they are robust. Recent research has focused on the question of verifying whether networks do not alter their behavior under small perturbations in inputs. Most successful methods are based on the paradigm of branch-and-bound, an abstraction-refinement technique. However, despite tremendous improvements in the last five years, there are still several benchmarks where these methods fail. One reason for this is that many methods use off-the-shelf methods to find the cause of imprecisions.  

  In this paper, our goal is to develop an approach to identify the precise source of imprecision during abstraction. We present a {\em novel} counterexample guided approach that can be applied alongside many abstraction techniques. As a specific case, we implement our technique on top of a basic abstraction framework provided by the tool~\deeppoly{} and demonstrate how we can remove imprecisions in a targetted manner. This allows us to go past~\deeppoly{}'s performance as well as significantly outperform other refinement approaches in literature. Surprisingly, we are also able to verify several benchmark instances on which all leading tools (as per their performance in the competition VNNCOMP'21) fail. 

  %  We have implemented the method as a prototype.
%  We compare the performance of our tool against leading tools from VNNCOMP 2021.
  %
 % Our experiments show that we can solve 172  verification problems that none of the tools   can solve.
  % Our experiments show that we are outperforming in comparison
  % to the related refinement techniques, also verifying the more
  % number of unique
  % benchmarks on which the state of the arts fails to verify. 
\end{abstract}

\section{Introduction}
\label{sec:intro}
\input{sections/intro.tex}

% % \clearpage

\section{A Motivating Example}
\label{sec:motivation}
\input{sections/motivation.tex}

\section{Preliminaries}
\label{sec:model}
\input{sections/prelim.tex}



\section{Algorithm}
\label{sec:algo}
\input{sections/algo.tex}
\input{sections/proofs} 



\section{Experiments}
\label{sec:experiments}
\input{sections/experiments.tex}

%\section{Related work}
%\label{sec:related}
%\input{sections/related.tex}


\section{Conclusion}
\label{sec:conclusion}
\input{sections/conclusion.tex}

\bibliographystyle{unsrt}
\bibliography{biblio}

%\appendix

%\input{sections/appendix.tex}

\end{document}

% --- do not erase below this line ----

%%% Local Variables:
%%% mode: latex
%%% TeX-master: t
%%% End:
