\documentclass{llncs}

\input{macro.tex}
%\setlength{\textfloatsep}{1mm}% Remove \textfloatsep

\title{Using counter-examples to improve Robustness Verification in Neural Networks}
\author{}
\institute{}
%\author{Mohammad Afzal\inst{1,2}\and Ashutosh Gupta\inst{1}\and Akshay S\inst{1}\and Supratik Chakraborty\inst{1}}

%\institute{Indian Institute of Technology, Bombay, India\and TCS Research, Pune, India}
% \date{April 2021}

\begin{document}

\maketitle

\begin{abstract}
  Given the pervasive use of neural networks in safety-critical systems, e. g., in autonomous vehicles, medical diagnosis, and speech recognition, it is important to ensure that they are robust under minor errors. Thus, a significant line of recent research has focussed on the question of Robustness verification, i.e., whether such networks do not alter their behavior under small perturbations in inputs. Most successful methods are based on the paradigm of branch-and-bound, an abstraction-refinement technique. However, despite tremendous improvements in the last five years, there are still several benchmarks where these methods fail. One reason for this is that these methods use off-the-shelf methods to find the reason for imprecisions before refinement.  % Therefore, the practical verification methods need to resolve the   trade-off between scalability and precision.

In this paper, our goal is to develop an approach to identify the precise source of imprecision during abstraction. More precisely, we present a {\em novel} counterexample guided abstraction refinement method that can be applied on top of most existing refinement techniques. As a specific illustration, we implement our technique on top of a basic abstraction framework provided by an existing tool~\deeppoly{} and demonstrate how we can remove imprecisions in a targetted manner. Doing this allows us to go past~\deeppoly{}'s performance as well as all other refinement-based approaches. Surprisingly, this already allows us to verify more than 172 benchmark instances on which leading tools (as illustrated by their performance in the competition VNNCOMP 2021) fail. 

  %  We have implemented the method as a prototype.
%  We compare the performance of our tool against leading tools from VNNCOMP 2021.
  %
 % Our experiments show that we can solve 172  verification problems that none of the tools   can solve.
  % Our experiments show that we are outperforming in comparison
  % to the related refinement techniques, also verifying the more
  % number of unique
  % benchmarks on which the state of the arts fails to verify. 
\end{abstract}

\section{Introduction}
\label{sec:intro}
\input{sections/intro.tex}

% \clearpage

\section{A Motivating Example}
\label{sec:motivation}
\input{sections/motivation.tex}
\clearpage
\section{Preliminaries}
\label{sec:model}
\input{sections/prelim.tex}



\section{Algorithm}
\label{sec:algo}
\input{sections/algo.tex}

\clearpage


%\section{Variations}
%\label{sec:variations}
% \input{variations.tex}

%\clearpage
\section{Experiments}
\label{sec:experiments}
\input{sections/experiments.tex}

\section{Related work}
\label{sec:related}
\input{sections/related.tex}


\section{Conclusion and Future work}
\label{sec:conclusion}
\input{sections/conclusion.tex}

\bibliographystyle{unsrt}
\bibliography{biblio}

\appendix

\input{sections/appendix.tex}

\end{document}

% --- do not erase below this line ----

%%% Local Variables:
%%% mode: latex
%%% TeX-master: t
%%% End:
