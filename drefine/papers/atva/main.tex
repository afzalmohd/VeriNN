% \documentclass[runningheads]{llncs}
\documentclass{llncs}

\input{macro.tex}
%\setlength{\textfloatsep}{1mm}% Remove \textfloatsep

% \usepackage{floatrow}
% Table float box with bottom caption, box width adjusted to content
% \newfloatcommand{capbtabbox}{table}[][\FBwidth]


\title{Using Counterexamples to Improve Robustness Verification in Neural Networks}
% \author{}
% \institute{}
\author{Mohammad Afzal\inst{1,2}\orcidID{0000-0002-6173-3959} \and
Ashutosh Gupta\inst{1}\orcidID{0009-0003-7755-2006} \and
S. Akshay\inst{1}\orcidID{0000-0002-2471-5997}}

\authorrunning{M. Afzal et al.}
\titlerunning{Using Counterexamples to Improve Robustness...}

\institute{Indian Institute of Technology Bombay, Mumbai, India\and TCS Research, Pune, India}
% \date{April 2021}

\begin{document}


\maketitle

\begin{abstract}
  Given the pervasive use of neural networks in safety-critical systems it is important to ensure that they are robust. Recent research has focused on the question of verifying whether networks do not alter their behavior under small perturbations in inputs. Most successful methods are based on the paradigm of branch-and-bound, an abstraction-refinement technique. However, despite tremendous improvements in the last five years, there are still several benchmarks where these methods fail. One reason for this is that many methods use off-the-shelf methods to find the cause of imprecisions.  

  In this paper, our goal is to develop an approach to identify the precise source of imprecision during abstraction. We present a {\em novel} counterexample guided approach that can be applied alongside many abstraction techniques. As a specific case, we implement our technique on top of a basic abstraction framework provided by the tool~\deeppoly{} and demonstrate how we can remove imprecisions in a targetted manner. This allows us to go past~\deeppoly{}'s performance as well as outperform other refinement approaches in literature. Surprisingly, we are also able to verify several benchmark instances on which all leading tools %(as per their performance of their recent version)
  fail. 
  \keywords{Neural Networks \and Abstraction Refinement \and Robustness verification \and Counterexample guided approaches}
\end{abstract}

\section{Introduction}
\label{sec:intro}
\input{sections/intro.tex}

% % \clearpage

\section{A Motivating Example}
\label{sec:motivation}
\input{sections/motivation.tex}

\section{Preliminaries}
\label{sec:model}
\input{sections/prelim.tex}



\section{Algorithm}
\label{sec:algo}
\input{sections/algo.tex}
\input{sections/proofs} 



\section{Experiments}
\label{sec:experiments}
\input{sections/experiments.tex}

%\section{Related work}
%\label{sec:related}
%\input{sections/related.tex}


\section{Conclusion}
\label{sec:conclusion}
\input{sections/conclusion.tex}

\bibliographystyle{unsrt}
\bibliography{biblio}

% \appendix

% \input{sections/appendix.tex}

\end{document}

% --- do not erase below this line ----

%%% Local Variables:
%%% mode: latex
%%% TeX-master: t
%%% End:
